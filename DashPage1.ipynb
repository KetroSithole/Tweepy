{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7db177eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing Dash_1.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile Dash_1.py\n",
    "\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')\n",
    "\n",
    "import streamlit as st\n",
    "import pandas as pd\n",
    "import plost\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import string\n",
    "import re\n",
    "#matplotlib inline\n",
    "from textblob import TextBlob, Word, Blobber\n",
    "from textblob.classifiers import NaiveBayesClassifier\n",
    "from textblob.taggers import NLTKTagger\n",
    "from PIL import Image\n",
    "#import text2emotion as te\n",
    "import os \n",
    "import base64\n",
    "import warnings\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import style\n",
    "style.use('ggplot')\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = set(stopwords.words('english'))\n",
    "st.set_option('deprecation.showPyplotGlobalUse', False)\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "\n",
    "main_bg = \"C:/Users/Takudzwa Stephen/Downloads/download (5).jpg\"\n",
    "main_bg_ext = \"jpg\"\n",
    "\n",
    "#############\n",
    "\n",
    "#st.set_page_config(layout='wide', initial_sidebar_state='expanded')\n",
    "\n",
    "with open(\"style.css\") as f:\n",
    "    st.markdown(f'<style>{f.read()}</style>', unsafe_allow_html=True)\n",
    "  \n",
    "st.title(\"Service Delivery in South Africa\")\n",
    "st.header(\"Early Detection of Civil Unrest Using Social Media Data\")\n",
    " \n",
    "st.sidebar.header('Datatude Dashboard')    \n",
    "st.sidebar.subheader('insights')\n",
    "\n",
    "#reading the dataset\n",
    "data1=pd.read_excel(\"Clean_twitter_data.xlsx\")\n",
    "data2=pd.read_csv(\"Twitter_text_data.csv\")\n",
    "\n",
    "Options = [\"Sentiment Analysis\", \"Data Visualisation\",\"Intelligence\"]\n",
    "bar = st.sidebar.selectbox(\"Select Option\", Options)\n",
    "if bar == \"Sentiment Analysis\" :\n",
    "    upload_file = st.file_uploader('Upload a file')\n",
    "    if st.button(\"Print dataset\"):\n",
    "        st.write(data2.head(15))\n",
    "    if st.button(\"Number of rows & columns\"):\n",
    "        print(st.write(data2.shape))\n",
    "    if st.button(\"Attributes names\"):\n",
    "        st.write(data2.columns)\n",
    "    if st.button(\"Print clean dataset\"):\n",
    "        st.write(data1.head(10))   \n",
    "        \n",
    "    st.write(\"Original & clean twitter comments\") \n",
    "    if st.button(\"Print original tweets\"):\n",
    "        st.write(data2[\"text\"].head(10))\n",
    "    if st.button(\"Print clean tweets\"):\n",
    "        st.write(data1[\"text\"].head(10))\n",
    "        \n",
    "\n",
    "    st.write('Upload dataset or text to clean and analyse')\n",
    "    with st.expander('Analyze text'):\n",
    "        text = st.text_input('Input text here: ')\n",
    "        if text:\n",
    "            blob = TextBlob(text)\n",
    "            st.write('Polarity: ', round(blob.sentiment.polarity,2))\n",
    "            st.write('Subjectivity: ', round(blob.sentiment.subjectivity,2))\n",
    "\n",
    "\n",
    "        pre = st.text_input('Clean text: ')\n",
    "        if pre:\n",
    "            st.write(cleantext.clean(pre, clean_all= False, extra_spaces=True ,\n",
    "                                     stopwords=True ,lowercase=True ,numbers=True , punct=True))\n",
    "\n",
    "    with st.expander('Analyze CSV'):\n",
    "        upl = st.file_uploader('Upload file')\n",
    "\n",
    "        def score(x):\n",
    "            blob1 = TextBlob(x)\n",
    "            return blob1.sentiment.polarity\n",
    "\n",
    "    #\n",
    "        def analyze(x):\n",
    "            if x >= 0.5:\n",
    "                return 'Positive'\n",
    "            elif x <= -0.5:\n",
    "                return 'Negative'\n",
    "            else:\n",
    "                return 'Neutral'\n",
    "\n",
    "    #\n",
    "        if upl:\n",
    "            df = pd.read_excel(upl)\n",
    "            del df['Unnamed: 0']\n",
    "            df['score'] = df['tweets'].apply(score)\n",
    "            df['analysis'] = df['score'].apply(analyze)\n",
    "            st.write(df.head(10))\n",
    "\n",
    "            @st.cache\n",
    "            def convert_df(df):\n",
    "                # IMPORTANT: Cache the conversion to prevent computation on every rerun\n",
    "                return df.to_csv().encode('utf-8')\n",
    "\n",
    "            csv = convert_df(df)\n",
    "\n",
    "            st.download_button(\n",
    "                label=\"Download data as CSV\",\n",
    "                data=csv,\n",
    "                file_name='sentiment.csv',\n",
    "                mime='text/csv',\n",
    "            )\n",
    "\n",
    "\n",
    "      \n",
    "    \n",
    "if bar ==\"Data Visualisation\":\n",
    "    st.text(\"Twitter Data\")\n",
    " \n",
    " #Sentiments bar graph\n",
    "    \n",
    "    if st.button(\"Sentiment counts \"):\n",
    "        fig=plt.figure(figsize = (10,5))\n",
    "        plt.title(\"Sentiment counts\")\n",
    "        sns.countplot(x = 'sentiment', data = data1)\n",
    "        st.write(fig)\n",
    "\n",
    "#Sentiment pie chart\n",
    "\n",
    "    if st.button(\"Sentiments pie chart\"):\n",
    "        fig = plt.figure(figsize = (7,7))\n",
    "        colors = (\"yellowgreen\", \"gold\", \"red\")\n",
    "        wp = {'linewidth':2, \"edgecolor\" : \"black\"}\n",
    "        tags = data1['sentiment'].value_counts()\n",
    "        explode = (0.1, 0.1, 0.1)\n",
    "        tags.plot(kind = 'pie', autopct = '%1.1f%%', shadow = True, colors = colors, startangle=90, wedgeprops = wp, explode = explode, label = '')\n",
    "        plt.title('distribution of sentiments')\n",
    "        st.write(fig)\n",
    "        \n",
    "# word cloud\n",
    "    if st.button(\"Word cloud\"):\n",
    "        df1 = pd.read_excel(\"clean_protest_data.xlsx\")\n",
    "\n",
    "        df1.drop_duplicates(subset = \"text\", keep = \"first\", inplace = True)\n",
    "\n",
    "        df1['text'] = df1['text'].str.replace(r\"RT\", \" \")\n",
    "\n",
    "        \n",
    "\n",
    "        def data_processing(text):\n",
    "            text = text.lower()\n",
    "            text = re.sub(r\"https\\S+\\www\\S+\",'', text, flags = re.MULTILINE)\n",
    "            text = re.sub(r'@\\S+','', str(text))\n",
    "            text = re.sub(r'[^\\w\\s]','', text)\n",
    "            text_tokens = word_tokenize(text)\n",
    "            filtered_text = [w for w in text_tokens if not w in stop_words]\n",
    "            return \" \".join(filtered_text)\n",
    "\n",
    "        df1.text = df1['text'].apply(data_processing)\n",
    "\n",
    "        #stemming\n",
    "        import nltk\n",
    "        from nltk.stem import PorterStemmer\n",
    "\n",
    "        stemmer = PorterStemmer()\n",
    "\n",
    "        df1['text'] = df1['text'].apply(lambda x: \" \".join([stemmer.stem(word) for word in x.split()]))\n",
    "\n",
    "\n",
    "        from nltk.stem.wordnet import WordNetLemmatizer\n",
    "\n",
    "        lemmatizer = WordNetLemmatizer()\n",
    "        df1['text'] = df1['text'].apply(lambda x: \" \".join([lemmatizer.lemmatize(word) for word in x.split()]))\n",
    "        df1['text'].head()\n",
    "\n",
    "        def polarity(text):\n",
    "            return TextBlob(text).sentiment.polarity\n",
    "\n",
    "        df1['polarity'] = df1['text'].apply(polarity)\n",
    "\n",
    "        def sentiment(label):\n",
    "            if label < 0:\n",
    "                return \"negative\"\n",
    "            elif label == 0:\n",
    "                return \"neutral\"\n",
    "            elif label > 0:\n",
    "                return \"positive\"\n",
    "\n",
    "        df1['sentiment'] = df1['polarity'].apply(sentiment)\n",
    "\n",
    "        # wordcloud library\n",
    "        from wordcloud import WordCloud\n",
    "\n",
    "        # joing the different text together\n",
    "        long_string = ','.join(list(df1['text'].values))\n",
    "        \n",
    "        \n",
    "        # Create some sample text\n",
    "        text = long_string\n",
    "\n",
    "        # Create and generate a word cloud image:\n",
    "        wordcloud = WordCloud().generate(text)\n",
    "\n",
    "        # Display the generated image:\n",
    "        plt.imshow(wordcloud, interpolation='bilinear')\n",
    "        plt.axis(\"off\")\n",
    "        plt.show()\n",
    "        st.pyplot()\n",
    "        \n",
    "#Sentiments over time\n",
    "    st.write(\"Sentiments over time\")\n",
    "    if st.button(\"Show sentiments over time plots\"):\n",
    "        # Create data\n",
    "        x = [\"19\",\"20\",\"21\",\"22\",\"23\",\"24\",\"25\",\"26\",\"27\",\"28\",\"29\"]\n",
    "        pos=[520,405,600,469,473,499,571,625,529,497,502]\n",
    "        neu=[1945,1203,1267,900,841,916,1403,1920,1502,1030,1005]\n",
    "        nev=[320,500,369,201,276,301,401,550,561,461,327]\n",
    "        \n",
    "        plt.plot(x,pos)\n",
    "        plt.plot(x,nev)\n",
    "        plt.plot(x,neu)\n",
    "        plt.ylabel(\"number of tweets\")\n",
    "        plt.xlabel(\"date(November)\")\n",
    "        plt.title(\"Sentiments over time\")\n",
    "        plt.legend(labels=['positive','negetive','neutral'])\n",
    "\n",
    "        st.pyplot() \n",
    "        \n",
    "if bar == \"Intelligence\" :\n",
    "    \n",
    "    pos=[520,405,600,469,473,499,571,625,529,497,502]\n",
    "    neu=[1945,1203,1267,900,841,916,1403,1920,1502,1030,1005]\n",
    "    nev=[320,500,369,201,276,301,401,550,561,461,327]\n",
    "    red=[.4,.4,.4,.4,.4,.4,.4,.4,.4,.4,.4]\n",
    "    x = [\"19\",\"20\",\"21\",\"22\",\"23\",\"24\",\"25\",\"26\",\"27\",\"28\",\"29\"]\n",
    "    y = [(nev[0]/(nev[0]+pos[0]+neu[0])), (nev[1]/(nev[1]+pos[1]+neu[1])), (nev[2]/(nev[2]+pos[2]+neu[2])), (nev[3]/(nev[3]+pos[3]+neu[3])),\n",
    "        (nev[4]/(nev[4]+pos[4]+neu[4])), (nev[5]/(nev[5]+pos[5]+neu[5])), (nev[6]/(nev[6]+pos[6]+neu[6])), (nev[7]/(nev[7]+pos[7]+neu[7])), \n",
    "        (nev[8]/(nev[8]+pos[8]+neu[8])), (nev[9]/(nev[9]+pos[9]+neu[9])), (nev[10]/(nev[10]+pos[10]+neu[10]))]\n",
    "    plt.title(\"Intelligence Detection\")\n",
    "    plt.ylabel(\"Level of negetivity\")\n",
    "    plt.xlabel(\"Date(November)\")\n",
    "    plt.plot(x,y)\n",
    "    plt.plot(x,red)\n",
    "    st.pyplot()\n",
    "    \n",
    "    st.image('./header.png')\n",
    "   \n",
    "\n",
    "\n",
    "    \n",
    "    st.write(\"for the love of big data*******\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa02dc56",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
